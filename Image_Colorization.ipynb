{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Colorization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download the Dataset"
      ],
      "metadata": {
        "id": "C9cLxb3n_jSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QYNDNxg--vI"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n",
        "\n",
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/mittalshubham/images256\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Directories"
      ],
      "metadata": {
        "id": "Uw2eWK5vBBif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('images/train/class/', exist_ok=True) \n",
        "os.makedirs('images/val/class/', exist_ok=True) \n",
        "\n",
        "test_file = open('/content/images256/files.csv', 'r')\n",
        "file_arr = test_file.readlines()\n",
        "\n",
        "file_arr.pop(0)\n",
        "\n",
        "for i, file in enumerate(file_arr):\n",
        "  filepath = file.split(',', 1)[0]\n",
        "\n",
        "  if i < 600:\n",
        "    os.rename('/content/images256/' + filepath, 'images/val/class/' + filepath.rsplit('/',1)[1])\n",
        "  elif i < 6000:\n",
        "    os.rename('/content/images256/' + filepath, 'images/train/class/' + filepath.rsplit('/',1)[1])"
      ],
      "metadata": {
        "id": "NhP07PeuBUfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Tools\n"
      ],
      "metadata": {
        "id": "KGdeZ75TjIVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from skimage.color import lab2rgb, rgb2lab, rgb2gray\n",
        "from skimage import io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import shutil, time"
      ],
      "metadata": {
        "id": "1UMuwMJ4jMEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to check if GPU is valiable\n",
        "use_gpu = torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "_0Pu5A9KjSqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "CYMqJXQDkf4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "# Start with the second half of the model: convolution and upsampling\n",
        "class ColorizationNet(nn.Module):\n",
        "  def __init__(self, input_size=128):\n",
        "    super(ColorizationNet, self).__init__()\n",
        "    MIDLEVEL_FEATURE_SIZE = 128\n",
        "\n",
        "    resnet = models.resnet18(num_classes=365)\n",
        "    # Change the weight of the first layer to receive grayscale input (single-channel)\n",
        "    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1))\n",
        "    # Extract midlevel features from resnet-gray\n",
        "    self.midlevel_resenet = nn.Sequential(*list(resnet.children())[0:6])\n",
        "\n",
        "    self.upsample = nn.Sequential(\n",
        "        nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Upsample(scale_factor=2),\n",
        "        nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.Upsample(scale_factor=2),\n",
        "        nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),\n",
        "        nn.Upsample(scale_factor=2)\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    # Pass the input through resnet-gray to extract features\n",
        "    midlevel_features = self.midlevel_resenet(input)\n",
        "    # Upscale the features to get colors\n",
        "    output = self.upsample(midlevel_features)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Ij0IyuKakrgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = ColorizationNet()"
      ],
      "metadata": {
        "id": "CVV6OtK3qBWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression is being used, so the mean square error will be used as the loss function\n",
        "# It will minimize the Euclidian distance between the predicted color value and the true color value\n",
        "# Model will tend to choose desaturated colors since they are less likely to be wrong according to the loss function than bright colors\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)"
      ],
      "metadata": {
        "id": "VTPepMqXsWtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Images to LAB"
      ],
      "metadata": {
        "id": "d537meg6tRda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GrayscaleImageFolder(datasets.ImageFolder):\n",
        "  # This will convert images to grayscale before loading\n",
        "  def __getitem__(self, index):\n",
        "    path, target = self.imgs[index]\n",
        "    img = self.loader(path)\n",
        "\n",
        "    if self.transform is not None:\n",
        "      img_original = self.transform(img)\n",
        "      img_original = np.asarray(img_original)\n",
        "      img_lab = rgb2lab(img_original)\n",
        "      img_lab = (img_lab + 128) / 255\n",
        "      img_ab = img_lab[:, :, 1:3]\n",
        "      img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n",
        "      img_original = rgb2gray(img_original)\n",
        "      img_original = torch.from_numpy(img_original).unsqueeze(0).float()\n",
        "\n",
        "    if self.target_transform is not None:\n",
        "      target = self.target_transform(target)\n",
        "    \n",
        "    return img_original, img_ab, target"
      ],
      "metadata": {
        "id": "XT2bGSlgtQNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data"
      ],
      "metadata": {
        "id": "Kc167bZjv62n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transforms for training and validation data\n",
        "train_transforms = transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip()])\n",
        "train_imagefolder = GrayscaleImageFolder('images/train', train_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=64, shuffle=True)\n",
        "\n",
        "# Validation\n",
        "val_transforms = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224)])\n",
        "val_imagefolder = GrayscaleImageFolder('images/val', val_transforms)\n",
        "val_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "ClE5_eCIuFaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "94u0Vn8jv-Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "  # This will track the training loss\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "  def reset(self):\n",
        "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val*n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count\n",
        "  \n",
        "def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n",
        "  # This will convert images back to RGB\n",
        "  plt.clf()\n",
        "  color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # Combine channels\n",
        "  color_image = color_image.transpose((1, 2, 0)) # Rescale for matplotlib\n",
        "  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n",
        "  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
        "  color_image = lab2rgb(color_image.astype(np.float64))\n",
        "  grayscale_input = grayscale_input.squeeze().numpy()\n",
        "\n",
        "  if save_path is not None and save_name is not None:\n",
        "    plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n",
        "    plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))"
      ],
      "metadata": {
        "id": "vjYEcu2iwIPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "CeaRleVuyaQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(val_loader, model, loss_fn, save_images, epoch):\n",
        "  model.eval()\n",
        "\n",
        "  # Prepare value counters and timers\n",
        "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
        "\n",
        "  end = time.time()\n",
        "  already_saved_images = False\n",
        "\n",
        "  for i, (input_gray, input_ab, target) in enumerate(val_loader):\n",
        "    data_time.update(time.time() - end)\n",
        "\n",
        "    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()\n",
        "\n",
        "    # Run the model and record loss\n",
        "    output_ab = model(input_gray)\n",
        "    loss = loss_fn(output_ab, input_ab)\n",
        "    losses.update(loss.item(), input_gray.size(0))\n",
        "\n",
        "    # Save images\n",
        "    if save_images and not already_saved_images:\n",
        "      already_saved_images = True\n",
        "      for j in range(min(len(output_ab), 10)):\n",
        "        save_path = {'grayscale': 'outputs/gray/', 'colorized': 'outputs/color/'}\n",
        "        save_name = 'img-{}-epoch-{}.jpg'.format(i * val_loader.batch_size + j, epoch)\n",
        "        to_rgb(input_gray[j].cpu(), ab_input=output_ab[j].detach().cpu(), save_path=save_path, save_name=save_name)\n",
        "\n",
        "    batch_time.update(time.time() - end)\n",
        "    end = time.time()\n",
        "\n",
        "    # Print the model accuracy\n",
        "    if i % 25 == 0:\n",
        "      print('Validate: [{0}/{1}]\\t'\n",
        "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
        "             i, len(val_loader), batch_time=batch_time, loss=losses))\n",
        "    \n",
        "    print('Finished validation.')\n",
        "    return losses.avg\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "GPhlX-Y1w0Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "sBK0pxlhycwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, loss_fn, optimizer, epoch):\n",
        "  print('Starting Epoch #{} ...'.format(epoch))\n",
        "  model.train()\n",
        "  \n",
        "  # Prepare value counters and timers\n",
        "  batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
        "\n",
        "  end = time.time()\n",
        "  for i, (input_gray, input_ab, target) in enumerate(train_loader):\n",
        "    \n",
        "    # Use GPU if available\n",
        "    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()\n",
        "\n",
        "    # Record time to load data (above)\n",
        "    data_time.update(time.time() - end)\n",
        "\n",
        "    # Run forward pass\n",
        "    output_ab = model(input_gray) \n",
        "    loss = loss_fn(output_ab, input_ab) \n",
        "    losses.update(loss.item(), input_gray.size(0))\n",
        "\n",
        "    # Compute the gradient and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Record time to do forward and backward passes\n",
        "    batch_time.update(time.time() - end)\n",
        "    end = time.time()\n",
        "\n",
        "    # Print model accuracy -- in the code below, val refers to value, not validation\n",
        "    if i % 25 == 0:\n",
        "      print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "            'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "            'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "            'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
        "              epoch, i, len(train_loader), batch_time=batch_time,\n",
        "             data_time=data_time, loss=losses)) \n",
        "\n",
        "  print('Finished training epoch #{}'.format(epoch))"
      ],
      "metadata": {
        "id": "M-no0vGQ0qnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model and loss function to GPU\n",
        "if use_gpu:\n",
        "  loss_fn = loss_fn.cuda()\n",
        "  model = model.cuda()"
      ],
      "metadata": {
        "id": "d7qW_X3G2Zk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output directories\n",
        "os.makedirs('outputs/color', exist_ok=True)\n",
        "os.makedirs('outputs/gray', exist_ok=True)\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "save_images = True\n",
        "best_losses = 1e10\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "1fNyFsO82gGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "  train(train_loader, model, loss_fn, optimizer, epoch)\n",
        "  with torch.no_grad():\n",
        "    losses = validate(val_loader, model, loss_fn, save_images, epoch)\n",
        "  if losses < best_losses:\n",
        "    best_losses = losses\n",
        "    torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1,losses))"
      ],
      "metadata": {
        "id": "Wx7oPjv02lqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}